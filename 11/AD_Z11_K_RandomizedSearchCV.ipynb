{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 13:27:19.198327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/2tytwy6d2ll1_kvk_k0j7vd00000gn/T/ipykernel_8394/4204620386.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_set = pd.read_csv('adult/adult.data', sep=\", \",header = None)\n",
      "/var/folders/k_/2tytwy6d2ll1_kvk_k0j7vd00000gn/T/ipykernel_8394/4204620386.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_set = pd.read_csv('adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n",
      "(15060, 41)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[41,]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikeras) (1.3.2)\n",
      "Requirement already satisfied: packaging>=0.21 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikeras) (23.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/apple/Projects/UJ_zajecia/venvp/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7fbc88bf4790&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7fbc88bf4790&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function build_model at 0x7fbc88bf4790>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install scikeras \n",
    "from scikeras.wrappers import KerasClassifier \n",
    "keras_class = KerasClassifier(build_model)\n",
    "keras_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "849/849 [==============================] - 2s 1ms/step - loss: 1.3081 - accuracy: 0.7871 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 2/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8290 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 3/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 4/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 5/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 6/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 8/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 9/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n",
      "Epoch 10/10\n",
      "849/849 [==============================] - 1s 1ms/step - loss: 3.8289 - accuracy: 0.7517 - val_loss: 3.9316 - val_accuracy: 0.7451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7fbc88bf4790&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7fbc88bf4790&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function build_model at 0x7fbc88bf4790>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_neurons=41\n",
       "\tn_hidden=2\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "keras_class.fit(X_train, y_train, epochs=100, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wykonajmy RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 11.1039 - accuracy: 0.2638 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 2/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 3/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 4/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 5/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 6/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 7/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 8/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 9/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 10/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 11/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 12/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 13/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 14/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 15/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 16/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 17/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 18/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 19/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 20/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 21/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 22/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 23/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 24/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 25/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 26/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 27/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 28/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 29/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 30/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 31/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 32/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 33/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 34/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 35/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 36/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 37/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 38/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 39/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 40/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 41/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 42/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 43/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 44/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 45/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 46/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 47/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 48/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 49/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 50/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 51/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 52/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 53/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 54/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 55/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 56/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 57/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 58/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 59/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 60/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 61/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 62/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 63/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 64/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 65/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 66/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 67/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 68/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 69/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 70/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 71/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 72/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 73/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 74/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 75/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 76/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 77/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 78/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 79/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 80/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 81/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 82/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 83/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 84/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 85/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 86/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 87/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 88/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 89/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 90/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 91/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 92/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 93/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 94/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 95/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 96/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 97/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 98/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 99/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "Epoch 100/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 11.4785 - accuracy: 0.2473 - val_loss: 11.2227 - val_accuracy: 0.2640\n",
      "315/315 [==============================] - 0s 1ms/step\n",
      "[CV] END ...........................n_hidden=2, n_neurons=85; total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "566/566 [==============================] - 1s 2ms/step - loss: 1.9946 - accuracy: 0.7801 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 2/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 3/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 4/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 5/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 7/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 8/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 9/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 10/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 13/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 14/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 17/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 18/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 19/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 21/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 22/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 23/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 24/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 25/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 26/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 27/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 28/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 29/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 30/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 31/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 32/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 33/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 35/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 36/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 39/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 41/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 42/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 43/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 44/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 46/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 47/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 48/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 49/100\n",
      "566/566 [==============================] - 1s 1ms/step - loss: 3.8134 - accuracy: 0.7528 - val_loss: 4.0729 - val_accuracy: 0.7360\n",
      "Epoch 50/100\n",
      "540/566 [===========================>..] - ETA: 0s - loss: 3.8116 - accuracy: 0.7529"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wykonaj RandomizedSearchCV na danych FashionMINT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
